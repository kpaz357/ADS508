{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc2076ce-61a2-4648-84d2-8ce54537b6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded train.csv to favorita/train.csv\n",
      "Downloaded transactions.csv to favorita/transactions.csv\n",
      "Downloaded stores.csv to favorita/stores.csv\n",
      "Downloaded items.csv to favorita/items.csv\n",
      "Downloaded oil.csv to favorita/oil.csv\n",
      "Downloaded holidays_events.csv to favorita/holidays_events.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# create local folder if it doesn't exist\n",
    "os.makedirs(\"favorita\", exist_ok=True)\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket = \"nexttrendco\"\n",
    "prefix = \"favorita/\"\n",
    "\n",
    "files = [\n",
    "    \"train.csv\", \"transactions.csv\", \"stores.csv\",\n",
    "    \"items.csv\", \"oil.csv\", \"holidays_events.csv\"\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    s3.download_file(bucket, prefix + file, f\"favorita/{file}\")\n",
    "    print(f\"Downloaded {file} to favorita/{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2453a374-bfd4-4a56-a491-32207fa58a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df_sales = pd.read_csv(\"favorita/train.csv\", nrows=200000, low_memory=False)  \n",
    "df_transactions = pd.read_csv(\"favorita/transactions.csv\")\n",
    "df_stores = pd.read_csv(\"favorita/stores.csv\")\n",
    "df_items = pd.read_csv(\"favorita/items.csv\")\n",
    "df_oil = pd.read_csv(\"favorita/oil.csv\")\n",
    "df_holidays = pd.read_csv(\"favorita/holidays_events.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f8d5729-ec19-4b72-9ed4-05e3f83be454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge datasets\n",
    "df = df_sales.merge(df_stores, on='store_nbr', how='left')\n",
    "df = df.merge(df_items, on='item_nbr', how='left')\n",
    "df = df.merge(df_transactions, on=['date', 'store_nbr'], how='left')\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df_oil['date'] = pd.to_datetime(df_oil['date'])\n",
    "df = df.merge(df_oil, on='date', how='left')\n",
    "\n",
    "df_holidays['date'] = pd.to_datetime(df_holidays['date'])\n",
    "df = df.merge(df_holidays, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ed89277-7070-4a49-b6af-9cef04201ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform data scrub\n",
    "df.drop_duplicates(inplace=True)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df[df['unit_sales'] >= 0]  # Remove negatives\n",
    "\n",
    "#fFill missing numerical with median\n",
    "num_cols = df.select_dtypes(include='number').columns\n",
    "df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
    "\n",
    "# fill missing categorical with mode\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "df[cat_cols] = df[cat_cols].fillna(df[cat_cols].mode().iloc[0])\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c90ef7a5-1735-440e-a594-4a65421362ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. feature engineering\n",
    "df['dayofweek'] = df['date'].dt.dayofweek\n",
    "df['is_weekend'] = df['dayofweek'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "df = df.sort_values(['item_nbr', 'date'])\n",
    "\n",
    "df['lag_7'] = df.groupby('item_nbr')['unit_sales'].shift(7)\n",
    "df['rolling_7'] = df.groupby('item_nbr')['unit_sales'].transform(lambda x: x.rolling(7, min_periods=1).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa2bd732-895e-4658-a522-c3a0c88720ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape before scaling: (199989, 25)\n",
      "Nulls in scaled features:\n",
      "lag_7                    0\n",
      "rolling_7                0\n",
      "promo_lag_interaction    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# fill missing lag/rolling values\n",
    "df['lag_7'] = df['lag_7'].fillna(0)\n",
    "df['rolling_7'] = df['rolling_7'].fillna(df['lag_7'])\n",
    "df['onpromotion'] = df['onpromotion'].fillna(0)\n",
    "df['promo_lag_interaction'] = df['onpromotion'] * df['lag_7']\n",
    "\n",
    "# confirm shape and nulls\n",
    "print(\"df shape before scaling:\", df.shape)\n",
    "print(\"Nulls in scaled features:\")\n",
    "print(df[['lag_7', 'rolling_7', 'promo_lag_interaction']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd42466c-79d4-4c4a-9273-b1149c9ca71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = ['lag_7', 'rolling_7', 'promo_lag_interaction']\n",
    "df[scaled_features] = scaler.fit_transform(df[scaled_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a47433c-41fd-4402-922c-0cbf5ffb7569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature Transformation\n",
    "cat_vars = ['family', 'city', 'state', 'type_y']\n",
    "df = pd.get_dummies(df, columns=cat_vars, drop_first=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = ['lag_7', 'rolling_7', 'promo_lag_interaction']\n",
    "df[scaled_features] = scaler.fit_transform(df[scaled_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e197c8dc-6769-4e27-8427-294278a6bf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature transformation complete. Shape: (199989, 74)\n"
     ]
    }
   ],
   "source": [
    "# feature Transformation\n",
    "# ensure scaled features are clean\n",
    "scaled_features = ['lag_7', 'rolling_7', 'promo_lag_interaction']\n",
    "df[scaled_features] = df[scaled_features].fillna(0)\n",
    "\n",
    "# 2. normalize numerical features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[scaled_features] = scaler.fit_transform(df[scaled_features])\n",
    "\n",
    "print(\"feature transformation complete. Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf96a984-ff5e-420a-b357-927283a9a5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 139992\n",
      "Val size: 29998\n",
      "Test size: 29999\n"
     ]
    }
   ],
   "source": [
    "# sort by date to maintain time order\n",
    "df = df.sort_values('date')\n",
    "\n",
    "# create splits: 70% train, 15% val, 15% test\n",
    "train_size = int(len(df) * 0.7)\n",
    "val_size = int(len(df) * 0.15)\n",
    "\n",
    "df_train = df.iloc[:train_size]\n",
    "df_val = df.iloc[train_size:train_size + val_size]\n",
    "df_test = df.iloc[train_size + val_size:]\n",
    "\n",
    "print(\"Train size:\", len(df_train))\n",
    "print(\"Val size:\", len(df_val))\n",
    "print(\"Test size:\", len(df_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "104d8d06-5778-4fce-a063-f3cff6eeb855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save processed splits\n",
    "df_train.to_csv(\"train.csv\", index=False)\n",
    "df_val.to_csv(\"val.csv\", index=False)\n",
    "df_test.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b01ad58-d302-4871-9c46-17ac4ff75e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded train.csv to s3://nexttrendco/favorita/processed/train.csv\n",
      "uploaded val.csv to s3://nexttrendco/favorita/processed/val.csv\n",
      "uploaded test.csv to s3://nexttrendco/favorita/processed/test.csv\n"
     ]
    }
   ],
   "source": [
    "# upload to S3\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3_bucket = \"nexttrendco\"\n",
    "\n",
    "datasets = {\n",
    "    \"train.csv\": \"favorita/processed/train.csv\",\n",
    "    \"val.csv\": \"favorita/processed/val.csv\",\n",
    "    \"test.csv\": \"favorita/processed/test.csv\"\n",
    "}\n",
    "\n",
    "for local_file, s3_key in datasets.items():\n",
    "    s3.upload_file(local_file, s3_bucket, s3_key)\n",
    "    print(f\"uploaded {local_file} to s3://{s3_bucket}/{s3_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f2b4994c-d08d-4f0b-8d65-0a4278e7bcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample CSVs created successfully \n"
     ]
    }
   ],
   "source": [
    "# adjust path if files are in a subfolder\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "val_df = pd.read_csv(\"val.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Take 1000-row samples (adjust if needed)\n",
    "train_df.sample(1000, random_state=42).to_csv(\"train_sample.csv\", index=False)\n",
    "val_df.sample(1000, random_state=42).to_csv(\"val_sample.csv\", index=False)\n",
    "test_df.sample(1000, random_state=42).to_csv(\"test_sample.csv\", index=False)\n",
    "\n",
    "print(\"Sample CSVs created successfully \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898aa541-126a-4651-a33a-423a6e03f743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
